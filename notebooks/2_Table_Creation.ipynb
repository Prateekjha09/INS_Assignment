{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8002efeb-a80d-42fe-a980-fa6953c88e91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9577a4cc-837a-41b6-8b60-f199ac58d22d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import to_date, current_timestamp\n",
    "from datetime import date\n",
    "import shutil\n",
    "import os\n",
    "from typing import List, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e9299b4-d69d-4038-b14d-64dc07e9efe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "NoDirective"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS inshort_cata.gold.content;\n",
    "DROP TABLE IF EXISTS inshort_cata.gold.content_stg;\n",
    "DROP TABLE IF EXISTS inshort_cata.gold.events;\n",
    "DROP TABLE IF EXISTS inshort_cata.gold.events_stg;\n",
    "DROP TABLE IF EXISTS inshort_cata.gold.users;\n",
    "DROP TABLE IF EXISTS inshort_cata.gold.users_stg;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d2c5fe2-e82c-4cf7-b323-3ad7f820367b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Delta lake tables creation based on parquet file uploaded to respective volumes in silver layer:\n",
    "\n",
    "**Content:** /Volumes/inshort_cata/silver/content_data\n",
    "\n",
    "**Events:** /Volumes/inshort_cata/silver/events_data\n",
    "\n",
    "**User:** /Volumes/inshort_cata/silver/user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c341db2-2ede-4332-af84-93eaf9aa1692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Time of execution for this code: ~ 3 mins\n",
    "def create_managed_table_from_volume(\n",
    "    volume_path: str,\n",
    "    table_name: str,\n",
    "    catalog: str = \"inshort_cata\",\n",
    "    schema: str = \"silver\",\n",
    "    zorder_cols: list = None,\n",
    "    optimize_after: bool = True\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Create optimized managed Delta table from volume path.\n",
    "    \n",
    "    Args:\n",
    "        volume_path: Path to volume containing parquet files\n",
    "        table_name: Target table name\n",
    "        catalog: Unity Catalog name\n",
    "        schema: Schema name\n",
    "        zorder_cols: Columns for Z-ORDER optimization\n",
    "        optimize_after: Enable OPTIMIZE and Z-ORDER\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful\n",
    "    \"\"\"\n",
    "    full_table_name = f\"{catalog}.{schema}.{table_name}\"\n",
    "    volume_path = volume_path.rstrip('/')\n",
    "    \n",
    "    try:\n",
    "        # Validate volume contents\n",
    "        files = dbutils.fs.ls(volume_path)\n",
    "        parquet_files = [f for f in files if f.name.lower().endswith('.parquet')]\n",
    "        \n",
    "        if not parquet_files:\n",
    "            return False\n",
    "        \n",
    "        # Drop existing table\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {full_table_name}\")\n",
    "        \n",
    "        # Create managed Delta table\n",
    "        df = spark.read.parquet(volume_path)\n",
    "        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(full_table_name)\n",
    "        \n",
    "        # Verify creation\n",
    "        row_count = spark.sql(f\"SELECT COUNT(*) as cnt FROM {full_table_name}\").collect()[0]['cnt']\n",
    "        \n",
    "        # Apply optimizations\n",
    "        if optimize_after:\n",
    "            spark.sql(f\"OPTIMIZE {full_table_name}\")\n",
    "            \n",
    "            zorder_columns = zorder_cols or [\"deviceid\"] if \"deviceid\" in [c.lower() for c in df.columns] else [\"_id\"]\n",
    "            if zorder_columns:\n",
    "                zorder_clause = \"ZORDER BY (\" + \", \".join(zorder_columns) + \")\"\n",
    "                spark.sql(f\"OPTIMIZE {full_table_name} {zorder_clause}\")\n",
    "            \n",
    "            # Set Delta table properties\n",
    "            spark.sql(f\"\"\"\n",
    "                ALTER TABLE {full_table_name} \n",
    "                SET TBLPROPERTIES (\n",
    "                    'delta.autoOptimize.optimizeWrite' = 'true',\n",
    "                    'delta.autoOptimize.autoCompact' = 'true',\n",
    "                    'delta.tuneFileSizesForRewrites' = 'true'\n",
    "                )\n",
    "            \"\"\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def create_all_tables() -> dict:\n",
    "    \"\"\"\n",
    "    Create all production tables with optimal configuration.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Status of each table creation\n",
    "    \"\"\"\n",
    "    table_configs = [\n",
    "        {\n",
    "            \"path\": \"/Volumes/inshort_cata/silver/user_data\",\n",
    "            \"name\": \"users\",\n",
    "            \"zorder\": [\"deviceid\", \"district\", \"install_date\"]\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/Volumes/inshort_cata/silver/events_data\", \n",
    "            \"name\": \"events\",\n",
    "            \"zorder\": [\"deviceid\", \"content_id\"]\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/Volumes/inshort_cata/silver/content_data\",\n",
    "            \"name\": \"content\", \n",
    "            \"zorder\": [\"_id\", \"author\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    for config in table_configs:\n",
    "        success = create_managed_table_from_volume(\n",
    "            config[\"path\"], \n",
    "            config[\"name\"], \n",
    "            zorder_cols=config[\"zorder\"]\n",
    "        )\n",
    "        results[config[\"name\"]] = success\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Production usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create individual tables\n",
    "    create_managed_table_from_volume(\n",
    "        \"/Volumes/inshort_cata/silver/user_data\", \n",
    "        \"users\"\n",
    "    )\n",
    "    \n",
    "    create_managed_table_from_volume(\n",
    "        \"/Volumes/inshort_cata/silver/events_data\", \n",
    "        \"events\"\n",
    "    )\n",
    "    \n",
    "    create_managed_table_from_volume(\n",
    "        \"/Volumes/inshort_cata/silver/content_data\", \n",
    "        \"content\"\n",
    "    )\n",
    "    \n",
    "    # Bulk creation with status tracking\n",
    "    creation_status = create_all_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c23b5e7-ec74-4cf4-b17f-89df2172a89b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Cross-verification of silver layer tables just loaded from files uploaded to different table specific Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b535c3-bb83-43ac-bf1a-7f3c4cd29d32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>113520</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         113520
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "count(1)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 56
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- One query to be run at a time for cross-checking proper data loading , Everything is looking normal till now\n",
    "\n",
    "select count(1) from inshort_cata.silver.content;\n",
    "--select count(1) from inshort_cata.silver.events;\n",
    "--select count(1) from inshort_cata.silver.users;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f600a755-653b-48d8-84db-df735b692fb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Add create statements here for gold layer: Reading streams of silver data and simultaneuosly put it in gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a693888e-47cc-4572-be25-a5a717907cf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Using Silver layer table for schema replication and adding a couple of more columns for SCD-2 tracking like effective_from, effective_to and is_active\n",
    "\n",
    "Creating empty final gold tables which will have SCD - 2 data for maintaining history which is to be used in DWH reports in the longer run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15869803-92af-4a19-ab2c-4d54cbeb7162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ensure_table_with_scd2(\n",
    "    source_table: str,\n",
    "    target_table: str,\n",
    "    scd2_cols: Dict[str, str] = None,\n",
    "    tbl_properties: Dict[str, str] = None,\n",
    "    zorder_cols: List[str] = None\n",
    "):\n",
    "    scd2_cols = scd2_cols or {\n",
    "        \"effective_from\": \"DATE\",\n",
    "        \"effective_to\": \"DATE\",\n",
    "        \"is_active\": \"BOOLEAN\"\n",
    "    }\n",
    "    tbl_properties = tbl_properties or {\n",
    "        \"delta.autoOptimize.optimizeWrite\": \"true\",\n",
    "        \"delta.autoOptimize.autoCompact\": \"true\"\n",
    "    }\n",
    "    zorder_cols = zorder_cols or list(scd2_cols.keys())\n",
    "\n",
    "    if not spark.catalog.tableExists(target_table):\n",
    "        empty_df = spark.table(source_table).limit(0)\n",
    "        empty_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(target_table)\n",
    "\n",
    "    existing_cols = [field.name for field in spark.table(target_table).schema.fields]\n",
    "    cols_to_add = [\n",
    "        f\"{col} {dtype}\" for col, dtype in scd2_cols.items() if col not in existing_cols\n",
    "    ]\n",
    "    if cols_to_add:\n",
    "        spark.sql(f\"ALTER TABLE {target_table} ADD COLUMNS ({', '.join(cols_to_add)})\")\n",
    "\n",
    "    props_str = \", \".join([f\"'{k}' = '{v}'\" for k, v in tbl_properties.items()])\n",
    "    spark.sql(f\"ALTER TABLE {target_table} SET TBLPROPERTIES ({props_str})\")\n",
    "\n",
    "    zorder_clause = f\"ZORDER BY ({', '.join(zorder_cols)})\"\n",
    "    spark.sql(f\"OPTIMIZE {target_table} {zorder_clause}\")\n",
    "\n",
    "# Tables details\n",
    "tables_config = [\n",
    "    {\n",
    "        \"source\": \"inshort_cata.silver.users\",\n",
    "        \"target\": \"inshort_cata.gold.users\",\n",
    "        \"zorder\": [\"deviceid\", \"district\", \"install_dt\"]\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"inshort_cata.silver.events\",\n",
    "        \"target\": \"inshort_cata.gold.events\",\n",
    "        \"zorder\": [\"deviceid\", \"content_id\"]\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"inshort_cata.silver.content\",\n",
    "        \"target\": \"inshort_cata.gold.content\",\n",
    "        \"zorder\": [\"_id\", \"author\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "for config in tables_config:\n",
    "    ensure_table_with_scd2(\n",
    "        source_table=config[\"source\"],\n",
    "        target_table=config[\"target\"],\n",
    "        zorder_cols=config[\"zorder\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e42e7b19-ad69-4d14-b8e0-1e2fda5b1500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "count(1)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 146
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "--select count(1) from inshort_cata.gold.content;\n",
    "--select count(1) from inshort_cata.gold.events;\n",
    "--select count(1) from inshort_cata.gold.users;\n",
    "\n",
    "-- Entire data count is and shoould be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a023030a-ed3a-4129-ad36-278773ee759e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Populating gold layer's staging tables with suffix \"_stg\" which can be used for evaluation or any other explicit transformation and then it can be MERGED to final gold layer table containing the cleanest form of data for advanced analytics and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0323c1e0-89c4-4cb0-a39e-fcc9675b82c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from pyspark.sql.functions import current_date, lit\n",
    "from datetime import date\n",
    "\n",
    "def populate_scd_staging_tables(\n",
    "    tables: list,\n",
    "    silver_prefix: str,\n",
    "    gold_prefix: str,\n",
    "    checkpoint_base: str\n",
    "):\n",
    "    for table in tables:\n",
    "        source_table = f\"{silver_prefix}.{table}\"\n",
    "        target_table = f\"{gold_prefix}.{table}_stg\"\n",
    "        checkpoint_path = f\"{checkpoint_base}/{table}_stg\"\n",
    "\n",
    "        # Remove previous checkpoint to avoid state conflicts\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            shutil.rmtree(checkpoint_path)\n",
    "\n",
    "        # Stream data from silver, add SCD2 columns, and write to gold staging\n",
    "        (\n",
    "            spark.readStream\n",
    "            .table(source_table)\n",
    "            .select(\n",
    "                \"*\",\n",
    "                current_date().alias(\"effective_from\"),\n",
    "                lit(date(9999, 12, 31)).alias(\"effective_to\"),\n",
    "                lit(True).alias(\"is_active\")\n",
    "            )\n",
    "            .writeStream\n",
    "            .format(\"delta\")\n",
    "            .option(\"checkpointLocation\", checkpoint_path)\n",
    "            .option(\"mergeSchema\", \"true\")\n",
    "            .trigger(once=True)\n",
    "            .toTable(target_table)\n",
    "        ).awaitTermination()\n",
    "\n",
    "tables_list = ['users', 'events', 'content']\n",
    "populate_scd_staging_tables(\n",
    "    tables=tables_list,\n",
    "    silver_prefix=\"inshort_cata.silver\",\n",
    "    gold_prefix=\"inshort_cata.gold\",\n",
    "    checkpoint_base=\"/Volumes/inshort_cata/gold/gold_data_checkpoint\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "641035c5-208d-4f4a-90ee-e7faf586033b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>42508</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         42508
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "count(1)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 173
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "--select count(1) from inshort_cata.gold.content_stg;\n",
    "--select count(1) from inshort_cata.gold.events_stg;\n",
    "--select count(1) from inshort_cata.gold.users_stg;\n",
    "\n",
    "-- Cross verification of staging table in gold layer: Everything looks fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3247e03-c5d8-4ae1-bd95-ba21f58cdf8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Implement SCD-2 for all 3 tables where source is \"_stg\" table of gold layer and then put the incremental data in gold based on MERGE: WIP\n",
    "\n",
    "At this point we have data only in silver and gold layer's staging environment, not in final gold tables which will be used for advanced analyics and reporting whose source of truth will be from main datawarehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03038ce2-5db1-4243-961f-95e04a6f31de",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764489217321}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def execute_scd2_merge_pipeline():\n",
    "    \"\"\"\n",
    "    Execute complete SCD2 MERGE pipeline for all tables.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Success status per table\n",
    "    \"\"\"\n",
    "    tables_list = ['users', 'events', 'content']\n",
    "    results = {}\n",
    "    \n",
    "    for table in tables_list:\n",
    "        try:\n",
    "            staging_table = f\"inshort_cata.gold.{table}_stg\"\n",
    "            target_table = f\"inshort_cata.gold.{table}\"\n",
    "            \n",
    "            # Verify staging table exists and has data\n",
    "            row_count = spark.sql(f\"SELECT COUNT(*) FROM {staging_table}\").collect()[0][0]\n",
    "            \n",
    "            if row_count == 0:\n",
    "                results[table] = False\n",
    "                continue\n",
    "            \n",
    "            # Table-specific MERGE logic\n",
    "            merge_sql = _generate_merge_sql(table, staging_table, target_table)\n",
    "            spark.sql(merge_sql)\n",
    "            \n",
    "            # Post-merge optimization\n",
    "            spark.sql(f\"OPTIMIZE {target_table} ZORDER BY (effective_from, is_active)\")\n",
    "            \n",
    "            # Verify post-merge active records\n",
    "            active_count = spark.sql(f\"\"\"\n",
    "                SELECT COUNT(*) \n",
    "                FROM {target_table} \n",
    "                WHERE is_active = TRUE\n",
    "            \"\"\").collect()[0][0]\n",
    "            \n",
    "            results[table] = True\n",
    "            \n",
    "        except Exception:\n",
    "            results[table] = False\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def _generate_merge_sql(table: str, staging_table: str, target_table: str) -> str:\n",
    "    \"\"\"Generate table-specific SCD2 MERGE SQL.\"\"\"\n",
    "    \n",
    "    table_configs = {\n",
    "        'users': {\n",
    "            'pk_cols': ['deviceid'],\n",
    "            'business_cols': ['lang', 'district', 'platform', 'install_dt', 'campaign_id']\n",
    "        },\n",
    "        'content': {\n",
    "            'pk_cols': ['_id'],\n",
    "            'business_cols': ['createdAt', 'newsLanguage', 'categories', 'author']\n",
    "        },\n",
    "        'events': {\n",
    "            'pk_cols': ['deviceid', 'content_id', 'eventtimestamp'],\n",
    "            'business_cols': ['timespent', 'eventname']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config = table_configs[table]\n",
    "    pk_condition = ' AND '.join([f'tgt.{col} = src.{col}' for col in config['pk_cols']])\n",
    "    change_condition = ' OR '.join([f'(tgt.{col} <> src.{col} OR (tgt.{col} IS NULL) <> (src.{col} IS NULL))' \n",
    "                                   for col in config['business_cols']])\n",
    "    insert_cols = ', '.join(config['pk_cols'] + config['business_cols'] + ['effective_from', 'effective_to', 'is_active'])\n",
    "    insert_values = ', '.join([f'src.{col}' for col in config['pk_cols'] + config['business_cols']] + \n",
    "                             ['current_date()', \"DATE '9999-12-31'\", 'TRUE'])\n",
    "    \n",
    "    return f\"\"\"\n",
    "    MERGE INTO {target_table} AS tgt\n",
    "    USING {staging_table} AS src\n",
    "    ON tgt.is_active = TRUE AND {pk_condition}\n",
    "    WHEN MATCHED AND ({change_condition}) THEN\n",
    "        UPDATE SET\n",
    "            tgt.effective_to = current_date(),\n",
    "            tgt.is_active = FALSE\n",
    "    WHEN NOT MATCHED THEN\n",
    "        INSERT ({insert_cols})\n",
    "        VALUES ({insert_values})\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Production execution\n",
    "if __name__ == \"__main__\":\n",
    "    merge_results = execute_scd2_merge_pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f59c778b-f867-4cd9-a301-fd53e95970e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'users': True, 'events': True, 'content': True}\n"
     ]
    }
   ],
   "source": [
    "print(merge_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36f57695-c4aa-47ba-9744-0eec7f56a428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Checking for normal counts for 1st incremental SCD-2 load and duplicate checks as well for each of the final gold layer tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c693933c-95a0-41b3-9cf6-9d03c0d06090",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764491499934}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>deviceid</th><th>count(deviceid)</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "deviceid",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "count(deviceid)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 187
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "deviceid",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count(deviceid)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select deviceid, count(deviceid) from inshort_cata.gold.users group by deviceid\n",
    "having count(deviceid) > 1\n",
    "order by 2 desc; -- No duplicates\n",
    "-- select count(1) from inshort_cata.gold.users;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6836092-13c7-4386-8ab2-d3cb75680638",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_id</th><th>count(_id)</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "_id",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "count(_id)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 189
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count(_id)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- select count(1) from inshort_cata.gold.content; -- 340560\n",
    "\n",
    "select _id, count(_id) from inshort_cata.gold.content\n",
    "group by _id\n",
    "having count(_id) > 1\n",
    "order by 2 desc; -- No duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2950858b-d63f-46e8-ab6b-02d8b0110f35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>82440945</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         82440945
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "count(1)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 190
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select count(1) from inshort_cata.gold.events;-- 82440945"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "359cef06-97ca-4a15-aa75-073ed5830216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Data loading along with SCD-2 implemented successfully!!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8287751117485554,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2_Table_Creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}